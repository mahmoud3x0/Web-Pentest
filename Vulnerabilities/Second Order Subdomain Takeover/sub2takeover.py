import requests
from bs4 import BeautifulSoup
import re
def get_links(url):
    response = requests.get(url, timeout=1.5).content
    soup = BeautifulSoup(response, "html.parser")
    return soup.find_all(lambda tag: tag.has_attr('href') or tag.has_attr('src'))

def check_2nd_order_subdomain_takeover(url):
    vulnerable = []
    try:
        urls = get_links(url)
        for u in urls:
            try:
                res1 = requests.get(u.get('src'), timeout=1.5)
                res2 = requests.get(u.get('href'), timeout=1.5)
            except:
                vulnerable.append(re.search(r'//([^/]+)', u.get('src')).group(1))

    except requests.exceptions as e:
        print("An error occurred, try again with valid input.")

    for i in set(vulnerable):
        print(f"[+] {i} may be vulnerable.")


if __name__ == "__main__":
    url = input("Enter the target URL: ")
    check_2nd_order_subdomain_takeover(url)




    
  
